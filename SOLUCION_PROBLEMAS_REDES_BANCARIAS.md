# ResoluciÃ³n de Problemas - Redes Neuronales en Banca

## ğŸ“‹ Resumen del Notebook

**Archivo**: `redes-neuronales-en-banca.ipynb`

**Objetivo**: Implementar una red neuronal para predecir si un cliente bancario dejarÃ¡ el banco (clasificaciÃ³n binaria) usando datos como geografÃ­a, gÃ©nero, edad, balance, etc.

**Dataset**: Bank_registries.csv - Datos bancarios con informaciÃ³n de clientes

---

## ğŸš¨ Problemas Identificados y Solucionados

### **1. Error Principal: OneHotEncoder con sintaxis obsoleta**

#### **âŒ Problema Original**

```python
# CÃ“DIGO ANTIGUO QUE FALLABA
onehotencoder = OneHotEncoder(categorical_features = [1])
X = onehotencoder.fit_transform(X).toarray()
X = X[:, 1:]
```

**Error**: `TypeError: OneHotEncoder.__init__() got an unexpected keyword argument 'categorical_features'`

#### **âœ… SoluciÃ³n Implementada**

```python
# CÃ“DIGO MODERNO Y FUNCIONAL
from sklearn.compose import ColumnTransformer

ct = ColumnTransformer(
    transformers=[('onehot', OneHotEncoder(drop='first'), [1])],
    remainder='passthrough'
)
X = ct.fit_transform(X)
```

**ExplicaciÃ³n**:

- `categorical_features` fue eliminado en scikit-learn >= 0.20
- `ColumnTransformer` es el mÃ©todo moderno y recomendado
- `drop='first'` evita la multicolinealidad (dummy trap)

---

### **2. Error CrÃ­tico: NameError - Variables no definidas**

#### **âŒ Problema Identificado**

```python
# ERROR DURANTE EL ENTRENAMIENTO
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500, verbose=1)
```

**Error**: `NameError: name 'X_train' is not defined`

#### **ğŸ” Causa del Problema**

- Las celdas de preprocessing no se ejecutaron en orden
- Variables como `X_train`, `y_train`, `X_test`, `y_test` no estÃ¡n disponibles
- El flujo de datos se interrumpiÃ³ o no se completÃ³

---

### **2.2 Error: NameError con variable 'dataset'**

#### **âŒ Problema Identificado**

```python
# ERROR EN SEPARACIÃ“N DE VARIABLES
X = dataset.iloc[:, 3:13].values
y = dataset.iloc[:, 13].values
```

**Error**: `NameError: name 'dataset' is not defined`

#### **ğŸ” Causa del Problema**

- La celda de carga de datos (celda 4) no se ejecutÃ³
- El kernel se reiniciÃ³ y se perdiÃ³ la variable `dataset`
- Se ejecutÃ³ la celda de separaciÃ³n de variables sin ejecutar primero la carga

#### **âœ… SoluciÃ³n Implementada - SeparaciÃ³n Robusta**

```python
# ğŸ”§ SEPARACIÃ“N DE VARIABLES CON VERIFICACIÃ“N ROBUSTA
print("ğŸ”§ Separando variables independientes (X) y dependiente (y)...")

# Verificar que dataset estÃ© definido
try:
    print(f"ğŸ“Š Dataset disponible: {dataset.shape}")
    print("âœ… Variable 'dataset' encontrada")
except NameError:
    print("âŒ Variable 'dataset' no encontrada")
    print("ğŸ”„ Ejecutando carga de datos...")

    # Cargar el dataset si no estÃ¡ definido
    try:
        dataset = pd.read_csv('Bank_registries.csv')
        print(f"âœ… Dataset cargado exitosamente: {dataset.shape}")
    except FileNotFoundError:
        print("âŒ Error: Archivo 'Bank_registries.csv' no encontrado")
        print("ğŸ“ Verifica que el archivo estÃ© en el directorio correcto")
        raise
    except Exception as e:
        print(f"âŒ Error al cargar el archivo: {e}")
        raise

# Separar variables
X = dataset.iloc[:, 3:13].values  # Variables independientes
y = dataset.iloc[:, 13].values    # Variable dependiente (Exited)

print(f"âœ… Variables separadas exitosamente:")
print(f"   â€¢ X shape: {X.shape}")
print(f"   â€¢ y shape: {y.shape}")
```

#### **ğŸ“‹ Ventajas de la SoluciÃ³n**

1. **VerificaciÃ³n automÃ¡tica** de la existencia de `dataset`
2. **Carga automÃ¡tica** si la variable no estÃ¡ definida
3. **Manejo de errores** para archivos no encontrados
4. **InformaciÃ³n detallada** sobre el estado de las variables
5. **DiagnÃ³stico completo** del flujo de datos

---

#### **âœ… SoluciÃ³n Implementada - ConfiguraciÃ³n AutomÃ¡tica**

```python
# ğŸ› ï¸ CONFIGURACIÃ“N COMPLETA AUTOMÃTICA
def configuracion_completa():
    global dataset, X, y, X_train, X_test, y_train, y_test, sc, classifier

    # 1. Cargar datos
    dataset = pd.read_csv('Bank_registries.csv')

    # 2. Separar variables
    X = dataset.iloc[:, 3:13].values
    y = dataset.iloc[:, 13].values

    # 3. Label Encoding
    labelencoder_X_1 = LabelEncoder()
    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])  # Geography
    labelencoder_X_2 = LabelEncoder()
    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])  # Gender

    # 4. One-Hot Encoding
    ct = ColumnTransformer(
        transformers=[('onehot', OneHotEncoder(drop='first'), [1])],
        remainder='passthrough'
    )
    X = ct.fit_transform(X)

    # 5. Train/Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 6. NormalizaciÃ³n
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)

    # 7. Crear y compilar modelo
    classifier = Sequential()
    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X.shape[1]))
    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))
    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return X_train, X_test, y_train, y_test
```

#### **âœ… SoluciÃ³n Implementada - Entrenamiento Robusto**

```python
# ğŸš€ ENTRENAMIENTO CON VERIFICACIÃ“N AUTOMÃTICA
try:
    print("ğŸ” Verificando variables...")
    print(f"   X_train: {X_train.shape}")
    print(f"   y_train: {y_train.shape}")
    print(f"   X_test: {X_test.shape}")
    print(f"   y_test: {y_test.shape}")
    print("âœ… Variables disponibles")
except NameError:
    print("âŒ Variables no disponibles")
    print("ğŸ”„ Ejecuta primero la celda de 'CONFIGURACIÃ“N COMPLETA AUTOMÃTICA'")
    raise

# Entrenar solo si las variables estÃ¡n disponibles
history = classifier.fit(
    X_train, y_train,
    batch_size=100,
    epochs=500,
    verbose=1,
    validation_split=0.1  # 10% para validaciÃ³n
)
```

#### **ğŸ“‹ Ventajas de la SoluciÃ³n**

1. **EjecuciÃ³n automÃ¡tica**: Un solo comando ejecuta todo el flujo
2. **VerificaciÃ³n robusta**: Checks antes de cada operaciÃ³n crÃ­tica
3. **Manejo de errores**: Mensajes claros sobre quÃ© hacer si algo falla
4. **Flujo completo**: Desde carga de datos hasta modelo compilado
5. **Reproducibilidad**: Seed fijo para resultados consistentes

---

### **2.1 AnÃ¡lisis Detallado del Error NameError**

#### **ğŸ” ExplicaciÃ³n TÃ©cnica del Error**

El error `NameError: name 'X_train' is not defined` ocurre cuando Python no puede encontrar la variable `X_train` en el espacio de nombres actual. Esto es especialmente comÃºn en notebooks de Jupyter porque las celdas se ejecutan de forma independiente.

#### **âš ï¸ Causa RaÃ­z del Problema**

```python
# SITUACIÃ“N PROBLEMÃTICA
# Celda 1: DefiniciÃ³n de variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Celda 2: Uso de variables (ejecutada sin ejecutar Celda 1)
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500)
# âŒ NameError: name 'X_train' is not defined
```

**Factores que contribuyen al error:**

1. **EjecuciÃ³n fuera de orden**: Las celdas se ejecutan en orden no secuencial
2. **Kernel reiniciado**: Se pierde el estado de todas las variables
3. **Celdas saltadas**: No se ejecutan las celdas de preprocessing
4. **Errores intermedios**: Fallos en celdas anteriores impiden la creaciÃ³n de variables

#### **ğŸ“Š Flujo de Dependencias**

```mermaid
graph TD
    A[Carga de datos] --> B[Preprocessing]
    B --> C[Label Encoding]
    C --> D[One-Hot Encoding]
    D --> E[Train/Test Split]
    E --> F[NormalizaciÃ³n]
    F --> G[CreaciÃ³n del modelo]
    G --> H[Entrenamiento]

    style H fill:#ffcccc
    style E fill:#ccffcc
```

**âš ï¸ Punto crÃ­tico**: Si la celda E (Train/Test Split) no se ejecuta correctamente, las variables `X_train`, `X_test`, `y_train`, `y_test` no existirÃ¡n para la celda H (Entrenamiento).

#### **ğŸ› ï¸ Estrategias de PrevenciÃ³n**

**1. VerificaciÃ³n AutomÃ¡tica de Variables**

```python
def verificar_variables_entrenamiento():
    """Verifica que todas las variables necesarias estÃ©n definidas"""
    variables_requeridas = ['X_train', 'X_test', 'y_train', 'y_test', 'classifier']
    variables_faltantes = []

    for var in variables_requeridas:
        if var not in globals():
            variables_faltantes.append(var)

    if variables_faltantes:
        print(f"âŒ Variables faltantes: {variables_faltantes}")
        print("ğŸ”„ Ejecuta las celdas de preprocessing en orden")
        return False
    else:
        print("âœ… Todas las variables estÃ¡n disponibles")
        return True

# Usar antes del entrenamiento
if verificar_variables_entrenamiento():
    # Proceder con el entrenamiento
    history = classifier.fit(X_train, y_train, batch_size=100, epochs=500)
```

**2. Checkpoint de Estado**

```python
def guardar_estado_variables():
    """Guarda informaciÃ³n sobre las variables actuales"""
    estado = {
        'X_train_shape': X_train.shape if 'X_train' in globals() else None,
        'y_train_shape': y_train.shape if 'y_train' in globals() else None,
        'modelo_compilado': hasattr(classifier, 'optimizer') if 'classifier' in globals() else False
    }

    print("ğŸ“Š Estado actual de las variables:")
    for key, value in estado.items():
        print(f"   {key}: {value}")

    return estado

# Ejecutar despuÃ©s de cada etapa crÃ­tica
estado = guardar_estado_variables()
```

**3. EjecuciÃ³n Segura con Try-Except**

```python
def entrenamiento_seguro():
    """Entrenamiento con manejo de errores comprehensivo"""
    try:
        # Verificar variables de entrenamiento
        print("ğŸ” Verificando X_train...")
        print(f"   Forma: {X_train.shape}")
        print(f"   Tipo: {type(X_train)}")

        print("ğŸ” Verificando y_train...")
        print(f"   Forma: {y_train.shape}")
        print(f"   Tipo: {type(y_train)}")

        print("ğŸ” Verificando modelo...")
        print(f"   Compilado: {hasattr(classifier, 'optimizer')}")

        # Proceder con entrenamiento
        print("ğŸš€ Iniciando entrenamiento...")
        history = classifier.fit(
            X_train, y_train,
            batch_size=100,
            epochs=500,
            verbose=1,
            validation_split=0.1
        )

        print("âœ… Entrenamiento completado exitosamente")
        return history

    except NameError as e:
        print(f"âŒ Error de variable no definida: {e}")
        print("ğŸ”„ SoluciÃ³n: Ejecuta la celda de 'CONFIGURACIÃ“N COMPLETA AUTOMÃTICA'")
        return None

    except Exception as e:
        print(f"âŒ Error inesperado: {e}")
        print("ğŸ”§ Revisa la configuraciÃ³n del modelo y datos")
        return None

# Uso seguro
history = entrenamiento_seguro()
```

#### **ğŸ“‹ Checklist de ResoluciÃ³n**

Cuando aparezca el error `NameError: name 'X_train' is not defined`, seguir estos pasos:

**âœ… Paso 1**: Verificar ejecuciÃ³n de celdas

- [ ] Â¿Se ejecutÃ³ la celda de carga de datos?
- [ ] Â¿Se ejecutÃ³ la celda de preprocessing?
- [ ] Â¿Se ejecutÃ³ la celda de train_test_split?

**âœ… Paso 2**: Verificar el estado del kernel

- [ ] Â¿El kernel se reiniciÃ³ recientemente?
- [ ] Â¿Hay errores en celdas anteriores?
- [ ] Â¿Se importaron todas las librerÃ­as necesarias?

**âœ… Paso 3**: DiagnÃ³stico de variables

```python
# Ejecutar para diagnÃ³stico
print("Variables disponibles en el espacio de nombres:")
print([var for var in dir() if not var.startswith('_')])
```

**âœ… Paso 4**: SoluciÃ³n rÃ¡pida

- Ejecutar la celda de "CONFIGURACIÃ“N COMPLETA AUTOMÃTICA"
- Verificar que todas las variables se crearon correctamente
- Proceder con el entrenamiento

#### **ğŸ¯ Mejores PrÃ¡cticas**

1. **Siempre ejecutar celdas en orden** durante el desarrollo inicial
2. **Usar la funciÃ³n de configuraciÃ³n automÃ¡tica** para reproducibilidad
3. **Implementar verificaciones de estado** antes de operaciones crÃ­ticas
4. **Documentar dependencias** entre celdas claramente
5. **Crear checkpoints** despuÃ©s de operaciones costosas

Esta implementaciÃ³n robusta previene efectivamente el error `NameError` y proporciona herramientas de diagnÃ³stico claras para identificar y resolver problemas rÃ¡pidamente.

---

### **3. Importaciones de Keras Obsoletas**

#### **âŒ Problema Original**

```python
import keras
from keras.models import Sequential
from keras.layers import Dense
```

#### **âœ… SoluciÃ³n Implementada**

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
```

**ExplicaciÃ³n**:

- Keras se integrÃ³ completamente en TensorFlow 2.x
- `keras` standalone ya no se recomienda
- `tensorflow.keras` es la forma oficial

---

### **4. ParÃ¡metros de Dense() Obsoletos**

#### **âŒ Problema Original**

```python
classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))
classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))
classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
```

#### **âœ… SoluciÃ³n Implementada**

```python
classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X.shape[1]))
classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))
```

**Cambios realizados**:

- `output_dim` â†’ `units`
- `init` â†’ `kernel_initializer`
- `input_dim=11` â†’ `input_dim=X.shape[1]` (dinÃ¡mico)

---

### **5. ParÃ¡metros de fit() Obsoletos**

#### **âŒ Problema Original**

```python
classifier.fit(X_train, y_train, batch_size = 100, nb_epoch = 500)
```

#### **âœ… SoluciÃ³n Implementada**

```python
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500, verbose=1)

# MÃ©tricas adicionales
print(f"PÃ©rdida final: {history.history['loss'][-1]:.4f}")
print(f"PrecisiÃ³n final: {history.history['accuracy'][-1]:.4f}")
```

**Cambios realizados**:

- `nb_epoch` â†’ `epochs`
- Captura del historial para mÃ©tricas
- InformaciÃ³n adicional del entrenamiento

---

## ğŸ”„ Mejoras Adicionales Implementadas

### **1. ValidaciÃ³n de Dimensiones**

```python
print(f"Forma despuÃ©s de One-Hot Encoding: {X.shape}")
print(f"NÃºmero de caracterÃ­sticas despuÃ©s del preprocessing: {X.shape[1]}")
```

### **2. Resumen del Modelo**

```python
classifier.summary()
```

### **3. InformaciÃ³n Detallada del Preprocessing**

```python
print("DespuÃ©s del Label Encoding:")
print(f"Forma de X: {X.shape}")
print("Primeras 10 filas:")
print(X[0:10])
```

---

## ğŸ“Š Flujo de Datos Corregido

### **Paso 1: Carga de Datos**

```python
dataset = pd.read_csv('Bank_registries.csv')
X = dataset.iloc[:, 3:13].values  # Variables independientes
y = dataset.iloc[:, 13].values    # Variable dependiente (Exited)
```

### **Paso 2: Preprocessing**

1. **Label Encoding** para variables categÃ³ricas:

   - Geography (columna 1)
   - Gender (columna 2)

2. **One-Hot Encoding** para Geography:

   - Convierte 3 paÃ­ses en 2 columnas binarias (k-1)

3. **NormalizaciÃ³n** con StandardScaler:
   - Media = 0, DesviaciÃ³n estÃ¡ndar = 1

### **Paso 3: DivisiÃ³n de Datos**

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

### **Paso 4: ConstrucciÃ³n del Modelo**

```
Entrada (X.shape[1] caracterÃ­sticas)
    â†“
Capa Densa (6 neuronas, ReLU)
    â†“
Capa Densa (6 neuronas, ReLU)
    â†“
Capa Salida (1 neurona, Sigmoid)
```

### **Paso 5: Entrenamiento y EvaluaciÃ³n**

- Optimizador: Adam
- FunciÃ³n de pÃ©rdida: binary_crossentropy
- MÃ©trica: accuracy
- Ã‰pocas: 500, Batch size: 100

---

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### **Dependencias Requeridas**

```python
# LibrerÃ­as necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
```

### **Versiones Compatibles**

- **Python**: >= 3.7
- **TensorFlow**: >= 2.0
- **scikit-learn**: >= 0.20
- **pandas**: >= 1.0
- **numpy**: >= 1.18

---

## ğŸ“ˆ Arquitectura del Modelo Final

```
Modelo: Sequential
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense (Dense)                (None, 6)                 (X.shape[1]+1)*6
_________________________________________________________________
dense_1 (Dense)              (None, 6)                 42
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 7
=================================================================
Total params: Variable segÃºn X.shape[1]
Trainable params: Todos
Non-trainable params: 0
```

---

## ğŸ¯ Resultados Esperados

### **MÃ©tricas de EvaluaciÃ³n**

- **Accuracy**: ~80-85% (varÃ­a segÃºn datos)
- **Matriz de ConfusiÃ³n**: ClasificaciÃ³n binaria (0/1)
- **PÃ©rdida**: DisminuciÃ³n progresiva durante entrenamiento

### **InterpretaciÃ³n**

- **Verdaderos Positivos**: Clientes que efectivamente dejaron el banco
- **Verdaderos Negativos**: Clientes que permanecieron
- **Falsos Positivos**: Predicciones incorrectas de abandono
- **Falsos Negativos**: Clientes que abandonaron pero no se predijo

---

## ğŸ”§ Troubleshooting

### **Error ComÃºn 1**: Dimensiones incorrectas

```python
# Verificar siempre las dimensiones despuÃ©s del preprocessing
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
```

### **Error ComÃºn 2**: Archivo CSV no encontrado

```python
# Verificar la ubicaciÃ³n del archivo
import os
print(f"Directorio actual: {os.getcwd()}")
print(f"Archivos disponibles: {os.listdir('.')}")
```

### **Error ComÃºn 3**: Kernel no configurado

- Asegurar que el kernel tenga TensorFlow instalado
- Reiniciar el kernel despuÃ©s de instalar nuevas librerÃ­as

---

## ğŸ“š Conceptos Clave Explicados

### **One-Hot Encoding vs Dummy Encoding**

- **One-Hot**: k columnas para k categorÃ­as
- **Dummy**: k-1 columnas para k categorÃ­as (evita multicolinealidad)

### **Funciones de ActivaciÃ³n**

- **ReLU**: `max(0, x)` - Para capas ocultas
- **Sigmoid**: `1/(1+e^(-x))` - Para clasificaciÃ³n binaria

### **Optimizador Adam**

- Combina momentum y RMSprop
- Adapta la tasa de aprendizaje automÃ¡ticamente
- Eficiente para redes neuronales

---

## ï¿½ Visualizaciones y AnÃ¡lisis GrÃ¡fico de Resultados

### **ğŸ“Š Resumen Ejecutivo de Visualizaciones**

| VisualizaciÃ³n               | Herramienta                 | PropÃ³sito                                | Estado          |
| --------------------------- | --------------------------- | ---------------------------------------- | --------------- |
| **MÃ©tricas Detalladas**     | ClasificaciÃ³n personalizada | AnÃ¡lisis completo de rendimiento         | âœ… Implementado |
| **Curvas de Entrenamiento** | Matplotlib                  | Monitoreo del progreso del entrenamiento | âœ… Implementado |
| **Matriz de ConfusiÃ³n**     | Seaborn Heatmap             | AnÃ¡lisis de errores y aciertos           | âœ… Implementado |
| **Curva ROC**               | Matplotlib                  | Capacidad discriminativa del modelo      | âœ… Implementado |
| **ComparaciÃ³n de Modelos**  | Matplotlib (Barras)         | ComparaciÃ³n visual de rendimiento        | âœ… Implementado |
| **AnÃ¡lisis de Errores**     | CÃ¡lculos personalizados     | IdentificaciÃ³n de patrones de errores    | âœ… Implementado |
| **Ensemble de Modelos**     | MÃºltiples modelos           | VisualizaciÃ³n de rendimiento combinado   | âœ… Implementado |
| **Grid Search**             | BÃºsqueda exhaustiva         | OptimizaciÃ³n de hiperparÃ¡metros          | âœ… Implementado |
| **ValidaciÃ³n Cruzada**      | KFold                       | EvaluaciÃ³n de estabilidad del modelo     | âœ… Implementado |

### **ğŸ¯ Resumen de Visualizaciones Implementadas**

Se han implementado **9 tipos diferentes de visualizaciones** profesionales para analizar y comparar el rendimiento de los modelos de redes neuronales, facilitando la interpretaciÃ³n de resultados y la toma de decisiones:

**ğŸ“ˆ Visualizaciones Principales:**

- **GrÃ¡ficos de Rendimiento**: Curvas de entrenamiento, loss y accuracy
- **Matrices de ConfusiÃ³n**: Heatmaps con anÃ¡lisis de errores
- **Curvas ROC**: AnÃ¡lisis de capacidad discriminativa
- **Comparaciones**: Modelos original vs mejorado vs ensemble

**ğŸ” AnÃ¡lisis Avanzado:**

- **DetecciÃ³n de Problemas**: IdentificaciÃ³n automÃ¡tica de overfitting, underfitting
- **OptimizaciÃ³n**: Grid search con visualizaciÃ³n de progreso
- **Estabilidad**: ValidaciÃ³n cruzada con anÃ¡lisis de varianza
- **Recomendaciones**: Sugerencias automÃ¡ticas basadas en mÃ©tricas

**ğŸ› ï¸ Herramientas Utilizadas:**

- **Matplotlib**: Para grÃ¡ficos de lÃ­nea, barras y curvas
- **Seaborn**: Para heatmaps y visualizaciones estadÃ­sticas
- **Scikit-learn**: Para mÃ©tricas y validaciÃ³n cruzada
- **TensorFlow/Keras**: Para el historial de entrenamiento

**ğŸ“‹ Beneficios de la ImplementaciÃ³n:**

1. **Interpretabilidad**: FÃ¡cil comprensiÃ³n visual de resultados
2. **DiagnÃ³stico**: IdentificaciÃ³n rÃ¡pida de problemas del modelo
3. **OptimizaciÃ³n**: GuÃ­a para mejoras y ajustes
4. **DocumentaciÃ³n**: Registro grÃ¡fico del rendimiento
5. **PresentaciÃ³n**: GrÃ¡ficos profesionales para reportes

---

### **1. ğŸ“ˆ AnÃ¡lisis de Rendimiento con MÃ©tricas Detalladas**

#### **ğŸ¯ Objetivo**

Proporcionar un anÃ¡lisis completo del rendimiento actual del modelo antes de aplicar mejoras.

#### **ğŸ“Š MÃ©tricas Visualizadas**

```python
# MÃ©tricas implementadas
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix

# AnÃ¡lisis de distribuciÃ³n de clases
unique, counts = np.unique(y_train, return_counts=True)
ratio_desbalance = counts[0] / counts[1]

# MÃ©tricas detalladas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred_proba)
```

#### **ğŸ“‹ InformaciÃ³n Mostrada**

- **DistribuciÃ³n de clases**: Porcentajes y counts de cada clase
- **Ratio de desbalance**: IdentificaciÃ³n de problemas de clases desbalanceadas
- **MÃ©tricas por clase**: Precision y Recall especÃ­ficos
- **Matriz de confusiÃ³n**: AnÃ¡lisis detallado de errores
- **IdentificaciÃ³n automÃ¡tica** de problemas de rendimiento

---

### **2. ğŸ—ï¸ VisualizaciÃ³n de Arquitectura del Modelo Mejorado**

#### **ğŸ¯ Objetivo**

Mostrar la evoluciÃ³n de la arquitectura del modelo desde el bÃ¡sico hasta el optimizado.

#### **ğŸ“Š Arquitectura Visualizada**

```python
# Modelo mejorado con visualizaciÃ³n
model_improved = Sequential([
    Dense(64, kernel_initializer='he_normal', activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(32, kernel_initializer='he_normal', activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(16, kernel_initializer='he_normal', activation='relu'),
    BatchNormalization(),
    Dropout(0.15),
    Dense(1, activation='sigmoid')
])

# Mostrar resumen del modelo
model_improved.summary()
```

#### **ğŸ“‹ InformaciÃ³n Mostrada**

- **NÃºmero de parÃ¡metros**: Total y por capa
- **ConfiguraciÃ³n de capas**: Neuronas, activaciones, regularizaciÃ³n
- **TÃ©cnicas implementadas**: Dropout, Batch Normalization, RegularizaciÃ³n L1/L2
- **ComparaciÃ³n** entre modelo original vs mejorado

---

### **3. ğŸ“Š VisualizaciÃ³n Comparativa de Modelos**

#### **ğŸ¯ Objetivo**

Comparar visualmente el rendimiento entre diferentes versiones del modelo.

#### **ğŸ“Š CÃ³digo de ComparaciÃ³n**

```python
# ComparaciÃ³n detallada de mÃ©tricas
print(f"{'MÃ©trica':<15} {'Original':<10} {'Mejorado':<10} {'Mejora':<10}")
print("-" * 50)

metricas = [
    ('Accuracy', accuracy_original, accuracy_improved),
    ('Precision', precision_original, precision_improved),
    ('Recall', recall_original, recall_improved),
    ('F1-Score', f1_original, f1_improved),
    ('AUC Score', auc_original, auc_improved)
]

for metrica, original, mejorado in metricas:
    mejora = ((mejorado - original) / original) * 100
    print(f"{metrica:<15} {original:<10.4f} {mejorado:<10.4f} {mejora:+7.2f}%")
```

#### **ğŸ“‹ InformaciÃ³n Mostrada**

- **Tabla comparativa**: Todas las mÃ©tricas lado a lado
- **Porcentaje de mejora**: CuantificaciÃ³n precisa de las mejoras
- **IdentificaciÃ³n automÃ¡tica**: QuÃ© mÃ©tricas mejoraron y cuÃ¡les no
- **AnÃ¡lisis de tendencias**: Mejora promedio y nÃºmero de mÃ©tricas mejoradas

---

### **4. ğŸ­ VisualizaciÃ³n de Ensemble de Modelos**

#### **ğŸ¯ Objetivo**

Mostrar cÃ³mo mÃºltiples modelos trabajando juntos mejoran el rendimiento.

#### **ğŸ“Š CÃ³digo de Ensemble**

```python
# Crear mÃºltiples modelos con diferentes configuraciones
ensemble_configs = [
    {'neurons1': 64, 'neurons2': 32, 'dropout_rate': 0.2},
    {'neurons1': 32, 'neurons2': 16, 'dropout_rate': 0.3},
    {'neurons1': 128, 'neurons2': 64, 'dropout_rate': 0.25}
]

# Entrenamiento y evaluaciÃ³n de cada modelo
for i, config in enumerate(ensemble_configs):
    # ... crear y entrenar modelo
    print(f"Modelo {i+1} accuracy: {individual_accuracy:.4f}")

# CombinaciÃ³n de predicciones
ensemble_pred = np.mean(predictions_ensemble, axis=0)
ensemble_accuracy = accuracy_score(y_test, ensemble_pred > 0.5)
```

#### **ğŸ“‹ InformaciÃ³n Mostrada**

- **Rendimiento individual**: Accuracy de cada modelo del ensemble
- **Rendimiento combinado**: Accuracy del ensemble completo
- **ComparaciÃ³n**: Ensemble vs mejor modelo individual
- **Mejora cuantificada**: Porcentaje de mejora del ensemble

---

### **5. ğŸ“ˆ GrÃ¡ficos Profesionales con Matplotlib**

#### **ğŸ¯ Objetivo**

Crear visualizaciones grÃ¡ficas profesionales para anÃ¡lisis visual de resultados.

#### **ğŸ“Š CÃ³digo de VisualizaciÃ³n**

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Crear figura con mÃºltiples subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('AnÃ¡lisis de Rendimiento del Modelo', fontsize=16)

# 1. Curvas de entrenamiento
ax1 = axes[0, 0]
ax1.plot(history_improved.history['accuracy'], label='Training Accuracy')
ax1.plot(history_improved.history['val_accuracy'], label='Validation Accuracy')
ax1.set_title('Curvas de Entrenamiento')
ax1.set_xlabel('Ã‰pocas')
ax1.set_ylabel('Accuracy')
ax1.legend()
ax1.grid(True)

# 2. Matriz de confusiÃ³n
ax2 = axes[0, 1]
sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Blues', ax=ax2)
ax2.set_title('Matriz de ConfusiÃ³n')
ax2.set_xlabel('PredicciÃ³n')
ax2.set_ylabel('Realidad')

# 3. Curva ROC
ax3 = axes[1, 0]
fpr, tpr, _ = roc_curve(y_test, y_pred_improved_proba)
ax3.plot(fpr, tpr, label=f'ROC (AUC = {auc_improved:.3f})')
ax3.plot([0, 1], [0, 1], 'k--', alpha=0.5)
ax3.set_title('Curva ROC')
ax3.set_xlabel('Tasa de Falsos Positivos')
ax3.set_ylabel('Tasa de Verdaderos Positivos')
ax3.legend()
ax3.grid(True)

# 4. ComparaciÃ³n de modelos
ax4 = axes[1, 1]
modelos = ['Original', 'Mejorado', 'Ensemble']
accuracies = [accuracy_original, accuracy_improved, ensemble_accuracy]
bars = ax4.bar(modelos, accuracies)
ax4.set_title('ComparaciÃ³n de Modelos')
ax4.set_ylabel('Accuracy')
ax4.set_ylim(0, 1)

# AÃ±adir valores en las barras
for bar, acc in zip(bars, accuracies):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
            f'{acc:.3f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()
```

#### **ğŸ“‹ GrÃ¡ficos Incluidos**

1. **Curvas de Entrenamiento**: Progreso del accuracy durante el entrenamiento
2. **Matriz de ConfusiÃ³n**: Heatmap con anotaciones de errores y aciertos
3. **Curva ROC**: AnÃ¡lisis del poder discriminativo del modelo
4. **ComparaciÃ³n de Modelos**: GrÃ¡fico de barras con accuracies comparativos

---

### **6. ğŸ” AnÃ¡lisis de Errores Visualizado**

#### **ğŸ¯ Objetivo**

Identificar patrones en los errores del modelo para mejoras futuras.

#### **ğŸ“Š MÃ©tricas de Error**

```python
# AnÃ¡lisis detallado de errores
fp_rate = cm_improved[0,1] / (cm_improved[0,1] + cm_improved[0,0])
fn_rate = cm_improved[1,0] / (cm_improved[1,0] + cm_improved[1,1])

print(f"Tasa de falsos positivos: {fp_rate:.3f}")
print(f"Tasa de falsos negativos: {fn_rate:.3f}")

# Recomendaciones automÃ¡ticas
if fn_rate > 0.3:
    print("â€¢ Considerar ajustar el threshold de clasificaciÃ³n")
if fp_rate > 0.2:
    print("â€¢ Implementar mÃ¡s regularizaciÃ³n")
if auc_improved < 0.85:
    print("â€¢ Considerar feature engineering adicional")
```

#### **ğŸ“‹ AnÃ¡lisis Incluido**

- **Tasas de error especÃ­ficas**: FP rate y FN rate
- **InterpretaciÃ³n de errores**: QuÃ© significan en el contexto bancario
- **Recomendaciones automÃ¡ticas**: Sugerencias basadas en las mÃ©tricas
- **Contexto de negocio**: Costo de falsos positivos vs falsos negativos

---

### **7. ğŸ¯ OptimizaciÃ³n de HiperparÃ¡metros Visualizada**

#### **ğŸ¯ Objetivo**

Mostrar el proceso de bÃºsqueda y optimizaciÃ³n de hiperparÃ¡metros.

#### **ğŸ“Š CÃ³digo de OptimizaciÃ³n**

```python
# Grid Search simplificado con visualizaciÃ³n de progreso
best_score = 0
best_params = {}

for neurons1 in [32, 64]:
    for dropout_rate in [0.2, 0.3]:
        for lr in [0.001, 0.0001]:
            print(f"Probando: neurons1={neurons1}, dropout={dropout_rate}, lr={lr}")

            # ... crear y entrenar modelo
            val_accuracy = max(history_temp.history['val_accuracy'])

            if val_accuracy > best_score:
                best_score = val_accuracy
                best_params = {...}
                print(f"âœ… Nuevo mejor score: {val_accuracy:.4f}")

print(f"\nğŸ¯ MEJORES HIPERPARÃMETROS:")
for param, value in best_params.items():
    print(f"   â€¢ {param}: {value}")
```

#### **ğŸ“‹ InformaciÃ³n Mostrada**

- **Progreso de bÃºsqueda**: Cada combinaciÃ³n probada
- **Mejores parÃ¡metros**: ConfiguraciÃ³n Ã³ptima encontrada
- **Mejora cuantificada**: Score del mejor modelo
- **Proceso transparente**: CÃ³mo se llegÃ³ a los mejores parÃ¡metros

---

### **8. ğŸ”„ ValidaciÃ³n Cruzada con Resultados**

#### **ğŸ¯ Objetivo**

Evaluar la estabilidad y robustez del modelo mediante validaciÃ³n cruzada.

#### **ğŸ“Š CÃ³digo de ValidaciÃ³n**

```python
from sklearn.model_selection import KFold

kfold = KFold(n_splits=3, shuffle=True, random_state=42)
cv_scores = []

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):
    print(f"Fold {fold + 1}/3...")

    # ... entrenar modelo en cada fold
    score = model_cv.evaluate(X_val_fold, y_val_fold, verbose=0)[1]
    cv_scores.append(score)
    print(f"Fold {fold + 1} accuracy: {score:.4f}")

print(f"Accuracy promedio: {np.mean(cv_scores):.4f}")
print(f"DesviaciÃ³n estÃ¡ndar: {np.std(cv_scores):.4f}")

if np.std(cv_scores) < 0.02:
    print("âœ… Modelo estable (baja varianza)")
else:
    print("âš ï¸  Modelo inestable (alta varianza)")
```

#### **ğŸ“‹ Resultados Mostrados**

- **Scores por fold**: Accuracy individual de cada divisiÃ³n
- **EstadÃ­sticas descriptivas**: Media y desviaciÃ³n estÃ¡ndar
- **AnÃ¡lisis de estabilidad**: InterpretaciÃ³n automÃ¡tica de la varianza
- **Confiabilidad del modelo**: QuÃ© tan consistente es el rendimiento

---

### **ğŸ“š Referencia RÃ¡pida de CÃ³digo para Visualizaciones**

#### **1. Curvas de Entrenamiento**

```python
# CÃ³digo bÃ¡sico para curvas de entrenamiento
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()
```

#### **2. Matriz de ConfusiÃ³n**

```python
# CÃ³digo para matriz de confusiÃ³n con seaborn
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()
```

#### **3. Curva ROC**

```python
# CÃ³digo para curva ROC
from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2,
         label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()
```

#### **4. ComparaciÃ³n de Modelos**

```python
# CÃ³digo para comparaciÃ³n de modelos
models = ['Original', 'Improved', 'Ensemble']
accuracies = [acc_original, acc_improved, acc_ensemble]

plt.figure(figsize=(10, 6))
bars = plt.bar(models, accuracies, color=['lightblue', 'lightgreen', 'lightcoral'])
plt.title('Model Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)

# Agregar valores en las barras
for bar, acc in zip(bars, accuracies):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{acc:.3f}', ha='center', va='bottom')

plt.grid(True, alpha=0.3)
plt.show()
```

#### **5. AnÃ¡lisis de DistribuciÃ³n de Clases**

```python
# CÃ³digo para anÃ¡lisis de distribuciÃ³n
unique, counts = np.unique(y_train, return_counts=True)
labels = ['No Churn', 'Churn']

plt.figure(figsize=(12, 4))

# GrÃ¡fico de barras
plt.subplot(1, 2, 1)
bars = plt.bar(labels, counts, color=['lightblue', 'lightcoral'])
plt.title('Class Distribution')
plt.ylabel('Count')
for bar, count in zip(bars, counts):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 50,
             f'{count}', ha='center', va='bottom')

# GrÃ¡fico de pastel
plt.subplot(1, 2, 2)
plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])
plt.title('Class Distribution (Percentage)')

plt.tight_layout()
plt.show()
```

#### **6. VisualizaciÃ³n de MÃ©tricas Detalladas**

```python
# CÃ³digo para mÃ©tricas detalladas
from sklearn.metrics import classification_report

# Reporte de clasificaciÃ³n
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))

# MÃ©tricas especÃ­ficas
metrics = {
    'Accuracy': accuracy_score(y_test, y_pred),
    'Precision': precision_score(y_test, y_pred),
    'Recall': recall_score(y_test, y_pred),
    'F1-Score': f1_score(y_test, y_pred),
    'AUC': roc_auc_score(y_test, y_pred_proba)
}

# VisualizaciÃ³n de mÃ©tricas
plt.figure(figsize=(10, 6))
metrics_names = list(metrics.keys())
metrics_values = list(metrics.values())

bars = plt.bar(metrics_names, metrics_values, color='skyblue')
plt.title('Model Performance Metrics')
plt.ylabel('Score')
plt.ylim(0, 1)

for bar, value in zip(bars, metrics_values):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,
             f'{value:.3f}', ha='center', va='bottom')

plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### **ğŸ¨ Consejos de PersonalizaciÃ³n**

**Colores Profesionales:**

```python
# Paleta de colores recomendada
colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']
```

**Estilo Matplotlib:**

```python
# Aplicar estilo profesional
plt.style.use('seaborn-v0_8')  # o 'default', 'ggplot'
```

**TamaÃ±os de Figura:**

```python
# TamaÃ±os recomendados
plt.figure(figsize=(12, 8))  # Para dashboards
plt.figure(figsize=(10, 6))  # Para grÃ¡ficos individuales
plt.figure(figsize=(8, 6))   # Para presentaciones
```

---

## ï¿½ğŸ“… Historial de Cambios

**Fecha**: 9 de julio de 2025

### **Cambios Principales**:

1. **Celda 9**: Actualizado Label Encoding con mejor documentaciÃ³n
2. **Celda 10**: Reemplazado OneHotEncoder obsoleto por ColumnTransformer
3. **Nueva Celda**: Agregada explicaciÃ³n de compatibilidad
4. **Celda 18**: Actualizado importaciones de Keras a TensorFlow
5. **Celda 20**: Corregido parÃ¡metros de Dense()
6. **Celda 25**: Actualizado parÃ¡metros de fit()

### **Mejoras de CÃ³digo**:

- Mensajes informativos sobre dimensiones
- Captura del historial de entrenamiento
- Resumen automÃ¡tico del modelo
- Mejor documentaciÃ³n en lÃ­nea

---

## ğŸš€ PrÃ³ximos Pasos Sugeridos

### **Mejoras Potenciales**:

1. **ValidaciÃ³n cruzada** para mejor evaluaciÃ³n
2. **RegularizaciÃ³n** (Dropout, L1/L2) para evitar overfitting
3. **Tuning de hiperparÃ¡metros** (nÃºmero de neuronas, Ã©pocas)
4. **VisualizaciÃ³n** del entrenamiento (loss curves)
5. **MÃ©tricas adicionales** (precision, recall, F1-score)

### **CÃ³digo de Ejemplo para Mejoras**:

```python
# Dropout para regularizaciÃ³n
from tensorflow.keras.layers import Dropout

classifier.add(Dense(units=6, activation='relu', input_dim=X.shape[1]))
classifier.add(Dropout(0.2))  # Dropout del 20%
classifier.add(Dense(units=6, activation='relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units=1, activation='sigmoid'))

# Early stopping
from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=10)
history = classifier.fit(X_train, y_train,
                        validation_split=0.2,
                        callbacks=[early_stop],
                        epochs=500, batch_size=100)
```

---

## ğŸ“ Soporte

Para dudas o problemas adicionales:

1. Verificar que todas las librerÃ­as estÃ©n actualizadas
2. Revisar la documentaciÃ³n de TensorFlow 2.x
3. Consultar este documento para errores comunes
4. Reiniciar el kernel si hay problemas de memoria

**Â¡El notebook estÃ¡ ahora completamente actualizado y funcional!** ğŸ‰ğŸ¦ğŸ¤–
