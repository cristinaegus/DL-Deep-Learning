# Resoluci√≥n de Problemas - Redes Neuronales en Banca

## üìã Resumen del Notebook

**Archivo**: `redes-neuronales-en-banca.ipynb`

**Objetivo**: Implementar una red neuronal para predecir si un cliente bancario dejar√° el banco (clasificaci√≥n binaria) usando datos como geograf√≠a, g√©nero, edad, balance, etc.

**Dataset**: Bank_registries.csv - Datos bancarios con informaci√≥n de clientes

---

## üö® Problemas Identificados y Solucionados

### **1. Error Principal: OneHotEncoder con sintaxis obsoleta**

#### **‚ùå Problema Original**

```python
# C√ìDIGO ANTIGUO QUE FALLABA
onehotencoder = OneHotEncoder(categorical_features = [1])
X = onehotencoder.fit_transform(X).toarray()
X = X[:, 1:]
```

**Error**: `TypeError: OneHotEncoder.__init__() got an unexpected keyword argument 'categorical_features'`

#### **‚úÖ Soluci√≥n Implementada**

```python
# C√ìDIGO MODERNO Y FUNCIONAL
from sklearn.compose import ColumnTransformer

ct = ColumnTransformer(
    transformers=[('onehot', OneHotEncoder(drop='first'), [1])],
    remainder='passthrough'
)
X = ct.fit_transform(X)
```

**Explicaci√≥n**:

- `categorical_features` fue eliminado en scikit-learn >= 0.20
- `ColumnTransformer` es el m√©todo moderno y recomendado
- `drop='first'` evita la multicolinealidad (dummy trap)

---

### **2. Error Cr√≠tico: NameError - Variables no definidas**

#### **‚ùå Problema Identificado**

```python
# ERROR DURANTE EL ENTRENAMIENTO
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500, verbose=1)
```

**Error**: `NameError: name 'X_train' is not defined`

#### **üîç Causa del Problema**

- Las celdas de preprocessing no se ejecutaron en orden
- Variables como `X_train`, `y_train`, `X_test`, `y_test` no est√°n disponibles
- El flujo de datos se interrumpi√≥ o no se complet√≥

#### **‚úÖ Soluci√≥n Implementada - Configuraci√≥n Autom√°tica**

```python
# üõ†Ô∏è CONFIGURACI√ìN COMPLETA AUTOM√ÅTICA
def configuracion_completa():
    global dataset, X, y, X_train, X_test, y_train, y_test, sc, classifier

    # 1. Cargar datos
    dataset = pd.read_csv('Bank_registries.csv')

    # 2. Separar variables
    X = dataset.iloc[:, 3:13].values
    y = dataset.iloc[:, 13].values

    # 3. Label Encoding
    labelencoder_X_1 = LabelEncoder()
    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])  # Geography
    labelencoder_X_2 = LabelEncoder()
    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])  # Gender

    # 4. One-Hot Encoding
    ct = ColumnTransformer(
        transformers=[('onehot', OneHotEncoder(drop='first'), [1])],
        remainder='passthrough'
    )
    X = ct.fit_transform(X)

    # 5. Train/Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 6. Normalizaci√≥n
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)

    # 7. Crear y compilar modelo
    classifier = Sequential()
    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X.shape[1]))
    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))
    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return X_train, X_test, y_train, y_test
```

#### **‚úÖ Soluci√≥n Implementada - Entrenamiento Robusto**

```python
# üöÄ ENTRENAMIENTO CON VERIFICACI√ìN AUTOM√ÅTICA
try:
    print("üîç Verificando variables...")
    print(f"   X_train: {X_train.shape}")
    print(f"   y_train: {y_train.shape}")
    print(f"   X_test: {X_test.shape}")
    print(f"   y_test: {y_test.shape}")
    print("‚úÖ Variables disponibles")
except NameError:
    print("‚ùå Variables no disponibles")
    print("üîÑ Ejecuta primero la celda de 'CONFIGURACI√ìN COMPLETA AUTOM√ÅTICA'")
    raise

# Entrenar solo si las variables est√°n disponibles
history = classifier.fit(
    X_train, y_train,
    batch_size=100,
    epochs=500,
    verbose=1,
    validation_split=0.1  # 10% para validaci√≥n
)
```

#### **üìã Ventajas de la Soluci√≥n**

1. **Ejecuci√≥n autom√°tica**: Un solo comando ejecuta todo el flujo
2. **Verificaci√≥n robusta**: Checks antes de cada operaci√≥n cr√≠tica
3. **Manejo de errores**: Mensajes claros sobre qu√© hacer si algo falla
4. **Flujo completo**: Desde carga de datos hasta modelo compilado
5. **Reproducibilidad**: Seed fijo para resultados consistentes

---

### **2.1 An√°lisis Detallado del Error NameError**

#### **üîç Explicaci√≥n T√©cnica del Error**

El error `NameError: name 'X_train' is not defined` ocurre cuando Python no puede encontrar la variable `X_train` en el espacio de nombres actual. Esto es especialmente com√∫n en notebooks de Jupyter porque las celdas se ejecutan de forma independiente.

#### **‚ö†Ô∏è Causa Ra√≠z del Problema**

```python
# SITUACI√ìN PROBLEM√ÅTICA
# Celda 1: Definici√≥n de variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Celda 2: Uso de variables (ejecutada sin ejecutar Celda 1)
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500)
# ‚ùå NameError: name 'X_train' is not defined
```

**Factores que contribuyen al error:**

1. **Ejecuci√≥n fuera de orden**: Las celdas se ejecutan en orden no secuencial
2. **Kernel reiniciado**: Se pierde el estado de todas las variables
3. **Celdas saltadas**: No se ejecutan las celdas de preprocessing
4. **Errores intermedios**: Fallos en celdas anteriores impiden la creaci√≥n de variables

#### **üìä Flujo de Dependencias**

```mermaid
graph TD
    A[Carga de datos] --> B[Preprocessing]
    B --> C[Label Encoding]
    C --> D[One-Hot Encoding]
    D --> E[Train/Test Split]
    E --> F[Normalizaci√≥n]
    F --> G[Creaci√≥n del modelo]
    G --> H[Entrenamiento]

    style H fill:#ffcccc
    style E fill:#ccffcc
```

**‚ö†Ô∏è Punto cr√≠tico**: Si la celda E (Train/Test Split) no se ejecuta correctamente, las variables `X_train`, `X_test`, `y_train`, `y_test` no existir√°n para la celda H (Entrenamiento).

#### **üõ†Ô∏è Estrategias de Prevenci√≥n**

**1. Verificaci√≥n Autom√°tica de Variables**

```python
def verificar_variables_entrenamiento():
    """Verifica que todas las variables necesarias est√©n definidas"""
    variables_requeridas = ['X_train', 'X_test', 'y_train', 'y_test', 'classifier']
    variables_faltantes = []

    for var in variables_requeridas:
        if var not in globals():
            variables_faltantes.append(var)

    if variables_faltantes:
        print(f"‚ùå Variables faltantes: {variables_faltantes}")
        print("üîÑ Ejecuta las celdas de preprocessing en orden")
        return False
    else:
        print("‚úÖ Todas las variables est√°n disponibles")
        return True

# Usar antes del entrenamiento
if verificar_variables_entrenamiento():
    # Proceder con el entrenamiento
    history = classifier.fit(X_train, y_train, batch_size=100, epochs=500)
```

**2. Checkpoint de Estado**

```python
def guardar_estado_variables():
    """Guarda informaci√≥n sobre las variables actuales"""
    estado = {
        'X_train_shape': X_train.shape if 'X_train' in globals() else None,
        'y_train_shape': y_train.shape if 'y_train' in globals() else None,
        'modelo_compilado': hasattr(classifier, 'optimizer') if 'classifier' in globals() else False
    }

    print("üìä Estado actual de las variables:")
    for key, value in estado.items():
        print(f"   {key}: {value}")

    return estado

# Ejecutar despu√©s de cada etapa cr√≠tica
estado = guardar_estado_variables()
```

**3. Ejecuci√≥n Segura con Try-Except**

```python
def entrenamiento_seguro():
    """Entrenamiento con manejo de errores comprehensivo"""
    try:
        # Verificar variables de entrenamiento
        print("üîç Verificando X_train...")
        print(f"   Forma: {X_train.shape}")
        print(f"   Tipo: {type(X_train)}")

        print("üîç Verificando y_train...")
        print(f"   Forma: {y_train.shape}")
        print(f"   Tipo: {type(y_train)}")

        print("üîç Verificando modelo...")
        print(f"   Compilado: {hasattr(classifier, 'optimizer')}")

        # Proceder con entrenamiento
        print("üöÄ Iniciando entrenamiento...")
        history = classifier.fit(
            X_train, y_train,
            batch_size=100,
            epochs=500,
            verbose=1,
            validation_split=0.1
        )

        print("‚úÖ Entrenamiento completado exitosamente")
        return history

    except NameError as e:
        print(f"‚ùå Error de variable no definida: {e}")
        print("üîÑ Soluci√≥n: Ejecuta la celda de 'CONFIGURACI√ìN COMPLETA AUTOM√ÅTICA'")
        return None

    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        print("üîß Revisa la configuraci√≥n del modelo y datos")
        return None

# Uso seguro
history = entrenamiento_seguro()
```

#### **üìã Checklist de Resoluci√≥n**

Cuando aparezca el error `NameError: name 'X_train' is not defined`, seguir estos pasos:

**‚úÖ Paso 1**: Verificar ejecuci√≥n de celdas

- [ ] ¬øSe ejecut√≥ la celda de carga de datos?
- [ ] ¬øSe ejecut√≥ la celda de preprocessing?
- [ ] ¬øSe ejecut√≥ la celda de train_test_split?

**‚úÖ Paso 2**: Verificar el estado del kernel

- [ ] ¬øEl kernel se reinici√≥ recientemente?
- [ ] ¬øHay errores en celdas anteriores?
- [ ] ¬øSe importaron todas las librer√≠as necesarias?

**‚úÖ Paso 3**: Diagn√≥stico de variables

```python
# Ejecutar para diagn√≥stico
print("Variables disponibles en el espacio de nombres:")
print([var for var in dir() if not var.startswith('_')])
```

**‚úÖ Paso 4**: Soluci√≥n r√°pida

- Ejecutar la celda de "CONFIGURACI√ìN COMPLETA AUTOM√ÅTICA"
- Verificar que todas las variables se crearon correctamente
- Proceder con el entrenamiento

#### **üéØ Mejores Pr√°cticas**

1. **Siempre ejecutar celdas en orden** durante el desarrollo inicial
2. **Usar la funci√≥n de configuraci√≥n autom√°tica** para reproducibilidad
3. **Implementar verificaciones de estado** antes de operaciones cr√≠ticas
4. **Documentar dependencias** entre celdas claramente
5. **Crear checkpoints** despu√©s de operaciones costosas

Esta implementaci√≥n robusta previene efectivamente el error `NameError` y proporciona herramientas de diagn√≥stico claras para identificar y resolver problemas r√°pidamente.

---

### **3. Importaciones de Keras Obsoletas**

#### **‚ùå Problema Original**

```python
import keras
from keras.models import Sequential
from keras.layers import Dense
```

#### **‚úÖ Soluci√≥n Implementada**

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
```

**Explicaci√≥n**:

- Keras se integr√≥ completamente en TensorFlow 2.x
- `keras` standalone ya no se recomienda
- `tensorflow.keras` es la forma oficial

---

### **4. Par√°metros de Dense() Obsoletos**

#### **‚ùå Problema Original**

```python
classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))
classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))
classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
```

#### **‚úÖ Soluci√≥n Implementada**

```python
classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X.shape[1]))
classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))
```

**Cambios realizados**:

- `output_dim` ‚Üí `units`
- `init` ‚Üí `kernel_initializer`
- `input_dim=11` ‚Üí `input_dim=X.shape[1]` (din√°mico)

---

### **5. Par√°metros de fit() Obsoletos**

#### **‚ùå Problema Original**

```python
classifier.fit(X_train, y_train, batch_size = 100, nb_epoch = 500)
```

#### **‚úÖ Soluci√≥n Implementada**

```python
history = classifier.fit(X_train, y_train, batch_size=100, epochs=500, verbose=1)

# M√©tricas adicionales
print(f"P√©rdida final: {history.history['loss'][-1]:.4f}")
print(f"Precisi√≥n final: {history.history['accuracy'][-1]:.4f}")
```

**Cambios realizados**:

- `nb_epoch` ‚Üí `epochs`
- Captura del historial para m√©tricas
- Informaci√≥n adicional del entrenamiento

---

## üîÑ Mejoras Adicionales Implementadas

### **1. Validaci√≥n de Dimensiones**

```python
print(f"Forma despu√©s de One-Hot Encoding: {X.shape}")
print(f"N√∫mero de caracter√≠sticas despu√©s del preprocessing: {X.shape[1]}")
```

### **2. Resumen del Modelo**

```python
classifier.summary()
```

### **3. Informaci√≥n Detallada del Preprocessing**

```python
print("Despu√©s del Label Encoding:")
print(f"Forma de X: {X.shape}")
print("Primeras 10 filas:")
print(X[0:10])
```

---

## üìä Flujo de Datos Corregido

### **Paso 1: Carga de Datos**

```python
dataset = pd.read_csv('Bank_registries.csv')
X = dataset.iloc[:, 3:13].values  # Variables independientes
y = dataset.iloc[:, 13].values    # Variable dependiente (Exited)
```

### **Paso 2: Preprocessing**

1. **Label Encoding** para variables categ√≥ricas:

   - Geography (columna 1)
   - Gender (columna 2)

2. **One-Hot Encoding** para Geography:

   - Convierte 3 pa√≠ses en 2 columnas binarias (k-1)

3. **Normalizaci√≥n** con StandardScaler:
   - Media = 0, Desviaci√≥n est√°ndar = 1

### **Paso 3: Divisi√≥n de Datos**

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

### **Paso 4: Construcci√≥n del Modelo**

```
Entrada (X.shape[1] caracter√≠sticas)
    ‚Üì
Capa Densa (6 neuronas, ReLU)
    ‚Üì
Capa Densa (6 neuronas, ReLU)
    ‚Üì
Capa Salida (1 neurona, Sigmoid)
```

### **Paso 5: Entrenamiento y Evaluaci√≥n**

- Optimizador: Adam
- Funci√≥n de p√©rdida: binary_crossentropy
- M√©trica: accuracy
- √âpocas: 500, Batch size: 100

---

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### **Dependencias Requeridas**

```python
# Librer√≠as necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
```

### **Versiones Compatibles**

- **Python**: >= 3.7
- **TensorFlow**: >= 2.0
- **scikit-learn**: >= 0.20
- **pandas**: >= 1.0
- **numpy**: >= 1.18

---

## üìà Arquitectura del Modelo Final

```
Modelo: Sequential
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense (Dense)                (None, 6)                 (X.shape[1]+1)*6
_________________________________________________________________
dense_1 (Dense)              (None, 6)                 42
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 7
=================================================================
Total params: Variable seg√∫n X.shape[1]
Trainable params: Todos
Non-trainable params: 0
```

---

## üéØ Resultados Esperados

### **M√©tricas de Evaluaci√≥n**

- **Accuracy**: ~80-85% (var√≠a seg√∫n datos)
- **Matriz de Confusi√≥n**: Clasificaci√≥n binaria (0/1)
- **P√©rdida**: Disminuci√≥n progresiva durante entrenamiento

### **Interpretaci√≥n**

- **Verdaderos Positivos**: Clientes que efectivamente dejaron el banco
- **Verdaderos Negativos**: Clientes que permanecieron
- **Falsos Positivos**: Predicciones incorrectas de abandono
- **Falsos Negativos**: Clientes que abandonaron pero no se predijo

---

## üîß Troubleshooting

### **Error Com√∫n 1**: Dimensiones incorrectas

```python
# Verificar siempre las dimensiones despu√©s del preprocessing
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
```

### **Error Com√∫n 2**: Archivo CSV no encontrado

```python
# Verificar la ubicaci√≥n del archivo
import os
print(f"Directorio actual: {os.getcwd()}")
print(f"Archivos disponibles: {os.listdir('.')}")
```

### **Error Com√∫n 3**: Kernel no configurado

- Asegurar que el kernel tenga TensorFlow instalado
- Reiniciar el kernel despu√©s de instalar nuevas librer√≠as

---

## üìö Conceptos Clave Explicados

### **One-Hot Encoding vs Dummy Encoding**

- **One-Hot**: k columnas para k categor√≠as
- **Dummy**: k-1 columnas para k categor√≠as (evita multicolinealidad)

### **Funciones de Activaci√≥n**

- **ReLU**: `max(0, x)` - Para capas ocultas
- **Sigmoid**: `1/(1+e^(-x))` - Para clasificaci√≥n binaria

### **Optimizador Adam**

- Combina momentum y RMSprop
- Adapta la tasa de aprendizaje autom√°ticamente
- Eficiente para redes neuronales

---

## üìÖ Historial de Cambios

**Fecha**: 9 de julio de 2025

### **Cambios Principales**:

1. **Celda 9**: Actualizado Label Encoding con mejor documentaci√≥n
2. **Celda 10**: Reemplazado OneHotEncoder obsoleto por ColumnTransformer
3. **Nueva Celda**: Agregada explicaci√≥n de compatibilidad
4. **Celda 18**: Actualizado importaciones de Keras a TensorFlow
5. **Celda 20**: Corregido par√°metros de Dense()
6. **Celda 25**: Actualizado par√°metros de fit()

### **Mejoras de C√≥digo**:

- Mensajes informativos sobre dimensiones
- Captura del historial de entrenamiento
- Resumen autom√°tico del modelo
- Mejor documentaci√≥n en l√≠nea

---

## üöÄ Pr√≥ximos Pasos Sugeridos

### **Mejoras Potenciales**:

1. **Validaci√≥n cruzada** para mejor evaluaci√≥n
2. **Regularizaci√≥n** (Dropout, L1/L2) para evitar overfitting
3. **Tuning de hiperpar√°metros** (n√∫mero de neuronas, √©pocas)
4. **Visualizaci√≥n** del entrenamiento (loss curves)
5. **M√©tricas adicionales** (precision, recall, F1-score)

### **C√≥digo de Ejemplo para Mejoras**:

```python
# Dropout para regularizaci√≥n
from tensorflow.keras.layers import Dropout

classifier.add(Dense(units=6, activation='relu', input_dim=X.shape[1]))
classifier.add(Dropout(0.2))  # Dropout del 20%
classifier.add(Dense(units=6, activation='relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units=1, activation='sigmoid'))

# Early stopping
from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=10)
history = classifier.fit(X_train, y_train,
                        validation_split=0.2,
                        callbacks=[early_stop],
                        epochs=500, batch_size=100)
```

---

## üìû Soporte

Para dudas o problemas adicionales:

1. Verificar que todas las librer√≠as est√©n actualizadas
2. Revisar la documentaci√≥n de TensorFlow 2.x
3. Consultar este documento para errores comunes
4. Reiniciar el kernel si hay problemas de memoria

**¬°El notebook est√° ahora completamente actualizado y funcional!** üéâüè¶ü§ñ
